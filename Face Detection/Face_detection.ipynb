{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection\n",
    "Implement a face tracking algorithm using haar cascade algorithm and OpenCV. Using\n",
    "haar cascade, first implement a face detection algorithm that counts the total number\n",
    "of faces present in any given frame. Write the total number of faces detected on the top\n",
    "left of the image. Further modify the code to track the face if only one face is detected.\n",
    "Make sure that you draw the bounding box corresponding to all video frames. Note: you\n",
    "may need to fine tune the parameters for Haar Cascade Classifier to get optimal results\n",
    "and remove false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an instancec of face classifier using haar cascade algorithm \n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the primary camera present on the device\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing an infinite loop for running a video\n",
    "while True:\n",
    "    # reading the data of single frame from camera for each iteration\n",
    "    ret, img = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        # converting the frame into a gray-scale image and storing it in a different variable, the original frame remains\n",
    "        gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # detecting the faces and their locations in the gray image\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        # drawing number of faces detected on image(not gray image) \n",
    "        image=cv2.putText(img,f\"number of faces detected : {len(faces)}\",(0,30), cv2.FONT_HERSHEY_PLAIN,2,(255,255,0),3)\n",
    "\n",
    "        # tracking the face if only one face is detedcted  \n",
    "        if len(faces)==1:     \n",
    "            # extracting the location of the dectected face    \n",
    "            left,top,width,height = faces[0]\n",
    "\n",
    "            # drawing a rectangle on the original frame to show tracking of a face\n",
    "            image=cv2.rectangle(image,(left,top),(left+width,top+height),color=(0,255,0))\n",
    "        \n",
    "        # showing the processed frame with both text and tracking\n",
    "        cv2.imshow('face detection assignment',image)\n",
    "\n",
    "        # setting a time-gap for the frame to be seen\n",
    "        k = cv2.waitKey(5) & 0xff\n",
    "\n",
    "        # condition for pressing escape key to end the infinite loop\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "# cleaning and closing \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
